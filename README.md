# Kathir ğŸ‘‹
**Data Engineer | MSc Data Science | UK**

I design and operate **production-grade data platforms** that turn raw, unreliable data into
**trusted, analytics-ready datasets**. My work focuses on **scalable ETL pipelines, data modelling,
and data quality**, with a strong emphasis on **correctness, reprocessing safety, and long-term
maintainability**.

ğŸŒ UK-based  
ğŸ’¼ Open to **Data Engineer / Analytics Engineer / Platform Data Engineer** roles

---

## ğŸ§  What I focus on
- Designing and owning **end-to-end ETL / ELT pipelines** (ingestion â†’ transformation â†’ consumption)
- Building **analytics-ready data models** (facts, dimensions, marts) that scale with business needs
- Writing **performant, cost-aware SQL** for large datasets
- Handling **late-arriving data, duplicates, schema drift, and backfills**
- Implementing **data validation, reconciliation, and auditability**
- Supporting analytics and reporting with **reliable, well-defined datasets**
- Making **engineering trade-offs** between correctness, performance, and cost
- Communicating data guarantees and limitations to **technical and non-technical stakeholders**

---

## ğŸ› ï¸ Tech Stack

### Data Engineering & Processing
- **SQL** (CTEs, window functions, optimisation, cost-aware design)
- **Python** (pipeline tooling, validation, automation)

### Data Platforms & Orchestration
- **AWS** (S3, Redshift, Athena)
- **Apache Airflow** (DAG design, retries, alerting, re-runs)

### Data Modelling & Analytics Engineering
- Dimensional modelling (**facts & dimensions**)
- **dbt** (models, tests, documentation)
- Incremental models & backfill-safe transformations

### Tools & Workflow
- Git
- Docker (reproducible data environments)
- Linux (CLI, basic ops)
- CI-friendly workflows for data pipelines

---

## ğŸ“‚ Featured Data Engineering Projects
> Repositories are added as projects mature and reach production-grade quality.

- **Production-Style Data Platform**  
  Raw â†’ staging â†’ curated layers with idempotent processing, schema validation, and auditability.

- **Incremental ETL & Backfill Framework**  
  Pipelines supporting late data, historical reprocessing, and deterministic outputs without duplication.

- **Analytics-Ready Data Models**  
  Fact and dimension tables optimised for reporting, trend analysis, and long-term consistency.

---

## ğŸ§© How I work
- Treat data pipelines as **production systems**, not scripts
- Assume **upstream data will break** and design for it
- Prefer **simple, maintainable designs** over fragile complexity
- Validate data before trusting metrics or reports
- Optimise for **reliability first**, then performance and cost
- Document assumptions and contracts so data remains trustworthy over time

---

## ğŸ“« Contact
- ğŸŒ Portfolio: https://kathirninja.github.io/kathiravan.github.io/
- ğŸ’¼ LinkedIn: https://www.linkedin.com/in/kathir8
- âœ‰ï¸ Email: iamkathiravan@outlook.com

---

â­ *Building data systems teams can trust â€” even when things go wrong.*
